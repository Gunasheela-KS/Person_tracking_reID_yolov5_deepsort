{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Environment** **Setup**"
      ],
      "metadata": {
        "id": "Bwieg6ueo4zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C761MGmnf-iu",
        "outputId": "7fd68035-b755-49af-b82f-c50aa44c68b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git  # clone repo\n",
        "%cd Yolov5_DeepSort_Pytorch\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The detections are performed using YOLOv5.\n",
        "*   yolov5 is a family of yolo object detection models pretrained on the COCO dataset.\n",
        "*   The detections are passed onto StrongSORT which combines motion and appearance information based on OSNet in order to tracks the objects. \n",
        "*   It can track any object that Yolov5 model was trained to detect."
      ],
      "metadata": {
        "id": "0OTUYO77zG92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download weights of yolov5m model trained on the crowd-human dataset**\n",
        "\n",
        "\n",
        "1.   create weights folder inside Yolov5_DeepSort_Pytorch\n",
        "2.   store the weights in the folder created\n",
        "\n"
      ],
      "metadata": {
        "id": "C0gO9oiBpMoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/releases/download*/v.2.0/crowdhuman_yolov5m.pt -O /content/Yolov5_DeepSort_Pytorch/weights/crowdhuman_yolov5m.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_EZwVIBgFg4",
        "outputId": "487cf71b-5f7f-4fde-dddb-3a4ad2bace7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-09-27 15:57:51--  https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/releases/download*/v.2.0/crowdhuman_yolov5m.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-09-27 15:57:52 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Take the test video and take out one minute video from it.\n",
        "2. Copy the video to local folder in .avi format  \n",
        "\n"
      ],
      "metadata": {
        "id": "OPS8XjBNpwAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the test video from the repo\n",
        "!wget -nc https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/releases/download/v.2.0/test.avi\n",
        "# extract 60 seconds worth of video frames of it\n",
        "!y | ffmpeg -ss 00:00:00 -i test.avi -t 00:01:00 -c copy out1.avi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7Mz6AFFiX1t",
        "outputId": "2b376065-ccd5-40e2-c975-a9c292f3adec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘test.avi’ already there; not retrieving.\n",
            "\n",
            "/bin/bash: y: command not found\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, matroska,webm, from 'test.avi':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isomiso2mp41\n",
            "    MAJOR_BRAND     : isom\n",
            "    MINOR_VERSION   : 512\n",
            "    ENCODER         : Lavf57.83.100\n",
            "  Duration: 00:00:35.00, start: 0.000000, bitrate: 1164 kb/s\n",
            "    Stream #0:0: Video: vp9 (Profile 0), yuv420p(tv, progressive), 960x540, SAR 1:1 DAR 16:9, 30 fps, 30 tbr, 1k tbn, 1k tbc (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : VideoHandler\n",
            "      ENCODER         : Lavc57.107.100 libvpx-vp9\n",
            "      DURATION        : 00:00:35.000000000\n",
            "Output #0, avi, to 'out1.avi':\n",
            "  Metadata:\n",
            "    COMPATIBLE_BRANDS: isomiso2mp41\n",
            "    MAJOR_BRAND     : isom\n",
            "    MINOR_VERSION   : 512\n",
            "    ISFT            : Lavf57.83.100\n",
            "    Stream #0:0: Video: vp9 (Profile 0) (VP90 / 0x30395056), yuv420p(tv, progressive), 960x540 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 30 tbr, 60 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      HANDLER_NAME    : VideoHandler\n",
            "      ENCODER         : Lavc57.107.100 libvpx-vp9\n",
            "      DURATION        : 00:00:35.000000000\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame= 1050 fps=0.0 q=-1.0 Lsize=    5022kB time=00:00:34.98 bitrate=1176.0kbits/s speed=3.46e+03x    \n",
            "video:4966kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.114366%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Convert .avi file to .mp4 format\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ObzV8zYF0OgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/Yolov5_DeepSort_Pytorch/out1.avi video1.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUx2tUn1nNsB",
        "outputId": "369f01e0-6989-46a5-c22f-b30bef3356d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/content/Yolov5_DeepSort_Pytorch/out1.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:35.00, start: 0.000000, bitrate: 1175 kb/s\n",
            "    Stream #0:0: Video: vp9 (Profile 0) (VP90 / 0x30395056), yuv420p(tv), 960x540, 1163 kb/s, SAR 1:1 DAR 16:9, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (vp9 (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mprofile High, level 3.2\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'video1.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 960x540 [SAR 1:1 DAR 16:9], q=-1--1, 60 fps, 15360 tbn, 60 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "\u001b[0;33mMore than 1000 frames duplicated\n",
            "frame= 2099 fps= 54 q=-1.0 Lsize=    4332kB time=00:00:34.93 bitrate=1015.9kbits/s dup=1049 drop=0 speed=0.897x    \n",
            "video:4307kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.590866%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mframe I:9     Avg QP:20.57  size: 48967\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mframe P:537   Avg QP:23.30  size:  6191\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mframe B:1553  Avg QP:30.48  size:   415\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mconsecutive B-frames:  0.5%  2.1%  1.1% 96.2%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mmb I  I16..4:  9.9% 68.1% 22.0%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mmb P  I16..4:  0.8%  1.6%  0.1%  P16..4: 32.8%  9.8%  7.2%  0.0%  0.0%    skip:47.7%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 18.0%  0.4%  0.1%  direct: 0.1%  skip:81.4%  L0:54.8% L1:42.9% BI: 2.2%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0m8x8 transform intra:65.1% inter:73.8%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mcoded y,uvDC,uvAC intra: 54.9% 63.0% 18.8% inter: 4.6% 5.9% 0.1%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mi16 v,h,dc,p: 17% 27% 18% 38%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 22% 31%  3%  4%  5%  4%  5%  5%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 31% 17% 12%  5%  7%  9%  5%  8%  5%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mi8c dc,h,v,p: 51% 22% 24%  3%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mref P L0: 69.8% 14.6% 12.0%  3.5%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mref B L0: 93.3%  5.8%  0.9%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mref B L1: 97.7%  2.3%\n",
            "\u001b[1;36m[libx264 @ 0x5635f0343e00] \u001b[0mkb/s:1008.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   By default the tracker tracks all MS COCO classes.\n",
        "\n",
        "*  For person tracking use **crowdhuman_yolov5m.pt** weights for increased performance\n",
        "\n",
        "\n",
        "*   --classes 0 # tracks persons, only\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1fB1Y2dh0y5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python track.py --source video1.mp4 --save-vid --strong-sort-weights osnet_x0_25_msmt17.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz8ej45Xiy5b",
        "outputId": "0665262b-2614-4b3c-f302-ae1b3e147b2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strong_sort/deep/reid/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n",
            "100% 40.8M/40.8M [00:00<00:00, 326MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Kkx2zW89jq_NETu4u42CFZTMVD5Hwm6e\n",
            "To: /content/Yolov5_DeepSort_Pytorch/osnet_x0_25_msmt17.pt\n",
            "100% 9.34M/9.34M [00:00<00:00, 198MB/s]\n",
            "Successfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   python track.py --save-vid saves the output video into runs folder.\n",
        "\n"
      ],
      "metadata": {
        "id": "dznIWcHj3nwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Person tracking"
      ],
      "metadata": {
        "id": "O_L5z0XVv5Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python track.py --source video1.mp4 --yolo-weights /content/Yolov5_DeepSort_Pytorch/weights/crowdhuman_yolov5m.pt --save-vid --classes 0  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stbSK9pZr0EU",
        "outputId": "34de6de0-3a4f-4758-d7e4-f50ddf504c2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strong_sort/deep/reid/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n",
            "Successfully loaded pretrained weights from \"/content/Yolov5_DeepSort_Pytorch/weights/osnet_x0_25_msmt17.pt\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python track.py --source \n",
        "\n",
        "\n",
        "\n",
        "*   0  # webcam\n",
        "*   img.jpg  # image\n",
        "*   vid.mp4  # video\n",
        "*   path/  # directory\n",
        "*   path/*.jpg  # glob\n",
        "*   'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "*   'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream                         "
      ],
      "metadata": {
        "id": "HfJtfd5nrQ9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "\n",
        "*   --classes 16 17\n",
        "*   cats and dogs tracking only\n",
        "\n"
      ],
      "metadata": {
        "id": "OQRd2l2G2rFO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmhlFN0n2nq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}